{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3554adba-cd75-48c3-b70c-221bd6926633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, models\n",
    "\n",
    "from ds import *\n",
    "from networks import *\n",
    "from utils import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d2c9aeb-62e9-4b67-b4c4-fba7b3aca56f",
   "metadata": {},
   "source": [
    "## Get data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f1d31c-cb32-4edc-99ca-e098962096e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfm = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor()\n",
    "])\n",
    "train_dset = CxVAE_Dset(\n",
    "    csv_file='../../../Datasets/chest_xray_pneumonia/train_labels.csv', \n",
    "    root_dir='../../../Datasets/chest_xray_pneumonia/images_224x256/',\n",
    "    tfm=train_tfm\n",
    ")\n",
    "val_dset = CxVAE_Dset(\n",
    "    csv_file='../../../Datasets/chest_xray_pneumonia/val_labels.csv', \n",
    "    root_dir='../../../Datasets/chest_xray_pneumonia/images_224x256/'\n",
    ")\n",
    "test_dset = CxVAE_Dset(\n",
    "    csv_file='../../../Datasets/chest_xray_pneumonia/test_labels.csv', \n",
    "    root_dir='../../../Datasets/chest_xray_pneumonia/images_224x256/'\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dset, batch_size=4, shuffle=True, num_workers=16, pin_memory=False)\n",
    "val_loader = DataLoader(val_dset, batch_size=4, shuffle=False, num_workers=16, pin_memory=False)\n",
    "test_loader = DataLoader(test_dset, batch_size=4, shuffle=False, num_workers=16, pin_memory=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "98cc203f-4546-4d87-a5c3-85bd6a407d61",
   "metadata": {},
   "source": [
    "## Define model and pass to the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c5af44-4037-47b8-a051-4c11ea05d66e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "Net = models.vgg16(pretrained=True, progress=False)\n",
    "print(Net)\n",
    "\n",
    "# Freeze training for all layers\n",
    "for param in Net.parameters():\n",
    "    param.require_grad = False\n",
    "\n",
    "# Newly created modules have require_grad=True by default\n",
    "num_features = Net.classifier[6].in_features\n",
    "fc_new = torch.nn.Linear(num_features, 2)\n",
    "Net.classifier[6] = fc_new\n",
    "print(Net)\n",
    "\n",
    "NetAE = AutoEncoder(3, 3, 8, 4, 32, 16)\n",
    "NetAE.load_state_dict(torch.load('../ckpt/AE_pneu_best.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a9e0f9-8b77-4621-9c48-199f3011173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classifier_w_AE_loop(\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    NetAE,\n",
    "    Net,\n",
    "    n_epochs=6,\n",
    "    init_lr=1e-6,\n",
    "    eval_every = 2,\n",
    "    dtype = torch.cuda.FloatTensor,\n",
    "    device='cuda',\n",
    "    ckpt_path = '../ckpt/VGG16_w_AE_pneu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593647b1-a06f-4b82-92e1-045bdc00e9af",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "Net.load_state_dict(torch.load('../ckpt/VGG16_w_AE_pneu_best.pth'))\n",
    "eval_classifier_w_AE_loop(\n",
    "    test_loader,\n",
    "    NetAE,\n",
    "    Net,\n",
    "    dtype = torch.cuda.FloatTensor,\n",
    "    device='cuda',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4288af-12de-49d3-9a05-3deafd7a37ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eeb89f-1335-430a-a4ef-dcc6e2acc883",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import Saliency\n",
    "from captum.attr import DeepLift\n",
    "from captum.attr import NoiseTunnel\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr import GuidedGradCam\n",
    "from captum.attr import InputXGradient\n",
    "\n",
    "import scipy\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6387b1-7fed-4d8d-91ba-d424d9da89c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Net.eval()\n",
    "def attribute_image_features(algorithm, input, label, **kwargs):\n",
    "    Net.zero_grad()\n",
    "    tensor_attributions = algorithm.attribute(\n",
    "        input,\n",
    "        target=label,\n",
    "        **kwargs\n",
    "    )\n",
    "    return tensor_attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdea7e48-09ee-48b5-895e-557647c3c556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_saliency_map(i1_rec, smap, alpha=0.5):\n",
    "    smap = (smap-np.min(smap))/(np.max(smap) - np.min(smap))\n",
    "    mask = smap > 0.75*np.max(smap)\n",
    "    smap = mask*smap\n",
    "    smap = np.mean(smap, axis=2)\n",
    "    smap = gaussian_filter(smap, sigma=10)\n",
    "    smap = (smap-np.min(smap))/(np.max(smap) - np.min(smap))\n",
    "    smap = np.uint8(smap*255)\n",
    "    smap = cv2.applyColorMap(smap, colormap=cv2.COLORMAP_PLASMA)\n",
    "    alpha = 0.5\n",
    "    i1_rec = np.uint8(i1_rec*255)\n",
    "    smap = cv2.addWeighted(i1_rec, alpha, smap, 1-alpha, 0)\n",
    "    return smap\n",
    "\n",
    "\n",
    "def show_classifier_w_AE_interp(\n",
    "    eval_loader,\n",
    "    NetAE,\n",
    "    Net,\n",
    "    dtype = torch.cuda.FloatTensor,\n",
    "    device='cuda',\n",
    "    n_show = 5,\n",
    "):\n",
    "    NetAE.to(device)\n",
    "    NetAE.type(dtype)\n",
    "    # Freeze training for all layers\n",
    "    for param in NetAE.parameters():\n",
    "        param.require_grad = False\n",
    "    NetAE.eval()\n",
    "    \n",
    "    Net.to(device)\n",
    "    Net.type(dtype)\n",
    "    Net.eval()\n",
    "    tot_err = 0\n",
    "    tot_samples = 0\n",
    "    for idx, (xin, yout) in enumerate(eval_loader):\n",
    "        if idx>= n_show:\n",
    "            break\n",
    "        xin, yout = xin.to(device), yout.to(device)\n",
    "        xin_rec, _ = NetAE(xin)\n",
    "        output = F.log_softmax(Net(xin_rec))\n",
    "        predictions = output.argmax(dim=1, keepdim=True).squeeze()\n",
    "        n_batch = xin.shape[0]\n",
    "        for j in range(n_batch):\n",
    "            i1 = xin[j].data.cpu().transpose(0,2).transpose(0,1).numpy()\n",
    "            i1_rec = xin_rec[j].data.cpu().transpose(0,2).transpose(0,1).clip(0,1).numpy()\n",
    "            \n",
    "            saliency = Saliency(Net)\n",
    "            grads = saliency.attribute(xin_rec[j].unsqueeze(0), target=yout[j].unsqueeze(0))\n",
    "            grads = np.transpose(grads.squeeze().data.cpu().detach().numpy(), (1, 2, 0))\n",
    "            \n",
    "            ig = IntegratedGradients(Net)\n",
    "            attr_ig, delta = attribute_image_features(ig, xin_rec[j].unsqueeze(0), yout[j], baselines=xin_rec[j].unsqueeze(0) * 0, return_convergence_delta=True)\n",
    "            attr_ig = np.transpose(attr_ig.squeeze().cpu().detach().numpy(), (1, 2, 0))\n",
    "            \n",
    "            ggcam = GuidedGradCam(Net, Net.features[10])\n",
    "            attr_ggcam = attribute_image_features(ggcam, xin_rec[j].unsqueeze(0), yout[j])\n",
    "            attr_ggcam = np.transpose(attr_ggcam.squeeze().cpu().detach().numpy(), (1, 2, 0))\n",
    "            \n",
    "            input_x_gradient = InputXGradient(Net)\n",
    "            attr_ixg = attribute_image_features(input_x_gradient, xin_rec[j].unsqueeze(0), yout[j])\n",
    "            attr_ixg = np.transpose(attr_ixg.squeeze().data.cpu().detach().numpy(), (1, 2, 0))\n",
    "            \n",
    "            grads = overlay_saliency_map(i1_rec, grads, alpha=0.5)\n",
    "            attr_ggcam = overlay_saliency_map(i1_rec, attr_ggcam, alpha=0.5)\n",
    "            attr_ig = overlay_saliency_map(i1_rec, attr_ig, alpha=0.5)\n",
    "            attr_ixg = overlay_saliency_map(i1_rec, attr_ixg, alpha=0.5)\n",
    "            \n",
    "            print('GT: {}, predicted: {}'.format(yout[j], predictions[j]))\n",
    "            \n",
    "            plt.figure(figsize=(24,8))\n",
    "            \n",
    "            plt.subplot(1,6,1)\n",
    "            plt.imshow(i1)\n",
    "            plt.axis('off')\n",
    "            plt.subplot(1,6,2)\n",
    "            plt.imshow(i1_rec)\n",
    "            plt.axis('off')\n",
    "            \n",
    "            plt.subplot(1,6,3)\n",
    "            ax = plt.gca()\n",
    "            im = ax.imshow(grads)\n",
    "            plt.axis('off')\n",
    "            divider = make_axes_locatable(ax)\n",
    "            cax = divider.append_axes(\"bottom\", size=\"5%\", pad=0.05)\n",
    "            plt.colorbar(im, cax=cax, orientation=\"horizontal\")\n",
    "            \n",
    "            plt.subplot(1,6,4)\n",
    "            ax = plt.gca()\n",
    "            im = ax.imshow(attr_ggcam)\n",
    "            plt.axis('off')\n",
    "            divider = make_axes_locatable(ax)\n",
    "            cax = divider.append_axes(\"bottom\", size=\"5%\", pad=0.05)\n",
    "            plt.colorbar(im, cax=cax, orientation=\"horizontal\")\n",
    "            \n",
    "            plt.subplot(1,6,5)\n",
    "            ax = plt.gca()\n",
    "            im = ax.imshow(attr_ig)\n",
    "            plt.axis('off')\n",
    "            divider = make_axes_locatable(ax)\n",
    "            cax = divider.append_axes(\"bottom\", size=\"5%\", pad=0.05)\n",
    "            plt.colorbar(im, cax=cax, orientation=\"horizontal\")\n",
    "            \n",
    "            plt.subplot(1,6,6)\n",
    "            ax = plt.gca()\n",
    "            im = ax.imshow(attr_ixg)\n",
    "            plt.axis('off')\n",
    "            divider = make_axes_locatable(ax)\n",
    "            cax = divider.append_axes(\"bottom\", size=\"5%\", pad=0.05)\n",
    "            plt.colorbar(im, cax=cax, orientation=\"horizontal\")\n",
    "            \n",
    "            \n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fc7c26-0e2c-47c8-9198-b522d3694fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_classifier_w_AE_interp(\n",
    "    test_loader,\n",
    "    NetAE,\n",
    "    Net,\n",
    "    dtype = torch.cuda.FloatTensor,\n",
    "    device='cuda',\n",
    "    n_show = 5,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
