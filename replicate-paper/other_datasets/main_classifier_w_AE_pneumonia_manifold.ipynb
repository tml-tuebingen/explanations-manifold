{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3554adba-cd75-48c3-b70c-221bd6926633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.image as mpimg\n",
    "!pip install seaborn\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "from scipy.linalg import orth\n",
    "from tqdm import tqdm\n",
    "import pickle as pkl\n",
    "from copy import deepcopy\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, utils, models\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.datasets import MNIST\n",
    "import random\n",
    "\n",
    "from ds import *\n",
    "from networks import *\n",
    "from utils import *\n",
    "\n",
    "!pip install captum\n",
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import Saliency\n",
    "from captum.attr import DeepLift\n",
    "from captum.attr import NoiseTunnel\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr import GuidedGradCam\n",
    "from captum.attr import GradientShap\n",
    "from captum.attr import InputXGradient\n",
    "\n",
    "import scipy\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d2c9aeb-62e9-4b67-b4c4-fba7b3aca56f",
   "metadata": {},
   "source": [
    "## Get data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f1d31c-cb32-4edc-99ca-e098962096e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfm = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor()\n",
    "])\n",
    "train_dset = CxVAE_Dset(\n",
    "    csv_file='../../../Datasets/chest_xray_pneumonia/train_labels.csv', \n",
    "    root_dir='../../../Datasets/chest_xray_pneumonia/images_224x256/',\n",
    "    tfm=train_tfm\n",
    ")\n",
    "val_dset = CxVAE_Dset(\n",
    "    csv_file='../../../Datasets/chest_xray_pneumonia/val_labels.csv', \n",
    "    root_dir='../../../Datasets/chest_xray_pneumonia/images_224x256/'\n",
    ")\n",
    "test_dset = CxVAE_Dset(\n",
    "    csv_file='../../../Datasets/chest_xray_pneumonia/test_labels.csv', \n",
    "    root_dir='../../../Datasets/chest_xray_pneumonia/images_224x256/'\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dset, batch_size=4, shuffle=True, num_workers=16, pin_memory=False)\n",
    "val_loader = DataLoader(val_dset, batch_size=4, shuffle=False, num_workers=16, pin_memory=False)\n",
    "test_loader = DataLoader(test_dset, batch_size=4, shuffle=False, num_workers=16, pin_memory=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "98cc203f-4546-4d87-a5c3-85bd6a407d61",
   "metadata": {},
   "source": [
    "## Define model and pass to the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c5af44-4037-47b8-a051-4c11ea05d66e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "Net = models.vgg16(pretrained=True, progress=False)\n",
    "print(Net)\n",
    "\n",
    "# Freeze training for all layers\n",
    "for param in Net.parameters():\n",
    "    param.require_grad = False\n",
    "\n",
    "# Newly created modules have require_grad=True by default\n",
    "num_features = Net.classifier[6].in_features\n",
    "fc_new = torch.nn.Linear(num_features, 2)\n",
    "Net.classifier[6] = fc_new\n",
    "print(Net)\n",
    "Net.load_state_dict(torch.load('../ckpt/VGG16_w_AE_pneu_best.pth'))\n",
    "\n",
    "NetAE = AutoEncoder(3, 3, 8, 4, 32, 16)\n",
    "NetAE.load_state_dict(torch.load('../ckpt/AE_pneu_best.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593647b1-a06f-4b82-92e1-045bdc00e9af",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_classifier_w_AE_loop(\n",
    "    test_loader,\n",
    "    NetAE,\n",
    "    Net,\n",
    "    dtype = torch.cuda.FloatTensor,\n",
    "    device='cuda',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6387b1-7fed-4d8d-91ba-d424d9da89c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attribute_image_features(algorithm, input, label, **kwargs):\n",
    "    tensor_attributions = algorithm.attribute(\n",
    "        input,\n",
    "        target=label,\n",
    "        **kwargs\n",
    "    )\n",
    "    return tensor_attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdea7e48-09ee-48b5-895e-557647c3c556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_saliency_map(i1_rec, smap, alpha=0.5):\n",
    "    smap = (smap-np.min(smap))/(np.max(smap) - np.min(smap))\n",
    "    mask = smap > 0.75*np.max(smap)\n",
    "    smap = mask*smap\n",
    "    smap = np.mean(smap, axis=2)\n",
    "    smap = gaussian_filter(smap, sigma=10)\n",
    "    smap = (smap-np.min(smap))/(np.max(smap) - np.min(smap))\n",
    "    smap = np.uint8(smap*255)\n",
    "    smap = cv2.applyColorMap(smap, colormap=cv2.COLORMAP_PLASMA)\n",
    "    alpha = 0.5\n",
    "    i1_rec = np.uint8(i1_rec*255)\n",
    "    smap = cv2.addWeighted(i1_rec, alpha, smap, 1-alpha, 0)\n",
    "    return smap\n",
    "\n",
    "\n",
    "def show_classifier_w_AE_interp(\n",
    "    eval_loader,\n",
    "    NetAE,\n",
    "    Net,\n",
    "    dtype = torch.cuda.FloatTensor,\n",
    "    device='cuda',\n",
    "    n_show = 5,\n",
    "):\n",
    "    NetAE.to(device)\n",
    "    NetAE.type(dtype)\n",
    "    # Freeze training for all layers\n",
    "    for param in NetAE.parameters():\n",
    "        param.require_grad = False\n",
    "    NetAE.eval()\n",
    "    \n",
    "    Net.to(device)\n",
    "    Net.type(dtype)\n",
    "    Net.eval()\n",
    "    tot_err = 0\n",
    "    tot_samples = 0\n",
    "    for idx, (xin, yout) in enumerate(eval_loader):\n",
    "        if idx>= n_show:\n",
    "            break\n",
    "        xin, yout = xin.to(device), yout.to(device)\n",
    "        xin_rec, _ = NetAE(xin)\n",
    "        output = F.log_softmax(Net(xin_rec))\n",
    "        predictions = output.argmax(dim=1, keepdim=True).squeeze()\n",
    "        n_batch = xin.shape[0]\n",
    "        for j in range(n_batch):\n",
    "            i1 = xin[j].data.cpu().transpose(0,2).transpose(0,1).numpy()\n",
    "            i1_rec = xin_rec[j].data.cpu().transpose(0,2).transpose(0,1).clip(0,1).numpy()\n",
    "            \n",
    "            saliency = Saliency(Net)\n",
    "            grads = saliency.attribute(xin_rec[j].unsqueeze(0), target=yout[j].unsqueeze(0))\n",
    "            grads = np.transpose(grads.squeeze().data.cpu().detach().numpy(), (1, 2, 0))\n",
    "            \n",
    "            ig = IntegratedGradients(Net)\n",
    "            attr_ig, delta = attribute_image_features(ig, xin_rec[j].unsqueeze(0), yout[j], baselines=xin_rec[j].unsqueeze(0) * 0, return_convergence_delta=True)\n",
    "            attr_ig = np.transpose(attr_ig.squeeze().cpu().detach().numpy(), (1, 2, 0))\n",
    "            \n",
    "            ggcam = GuidedGradCam(Net, Net.features[10])\n",
    "            attr_ggcam = attribute_image_features(ggcam, xin_rec[j].unsqueeze(0), yout[j])\n",
    "            attr_ggcam = np.transpose(attr_ggcam.squeeze().cpu().detach().numpy(), (1, 2, 0))\n",
    "            \n",
    "            input_x_gradient = InputXGradient(Net)\n",
    "            attr_ixg = attribute_image_features(input_x_gradient, xin_rec[j].unsqueeze(0), yout[j])\n",
    "            attr_ixg = np.transpose(attr_ixg.squeeze().data.cpu().detach().numpy(), (1, 2, 0))\n",
    "            \n",
    "            grads = overlay_saliency_map(i1_rec, grads, alpha=0.5)\n",
    "            attr_ggcam = overlay_saliency_map(i1_rec, attr_ggcam, alpha=0.5)\n",
    "            attr_ig = overlay_saliency_map(i1_rec, attr_ig, alpha=0.5)\n",
    "            attr_ixg = overlay_saliency_map(i1_rec, attr_ixg, alpha=0.5)\n",
    "            \n",
    "            print('GT: {}, predicted: {}'.format(yout[j], predictions[j]))\n",
    "            \n",
    "            plt.figure(figsize=(24,8))\n",
    "            \n",
    "            plt.subplot(1,6,1)\n",
    "            plt.imshow(i1)\n",
    "            plt.axis('off')\n",
    "            plt.subplot(1,6,2)\n",
    "            plt.imshow(i1_rec)\n",
    "            plt.axis('off')\n",
    "            \n",
    "            plt.subplot(1,6,3)\n",
    "            ax = plt.gca()\n",
    "            im = ax.imshow(grads)\n",
    "            plt.axis('off')\n",
    "            divider = make_axes_locatable(ax)\n",
    "            cax = divider.append_axes(\"bottom\", size=\"5%\", pad=0.05)\n",
    "            plt.colorbar(im, cax=cax, orientation=\"horizontal\")\n",
    "            \n",
    "            plt.subplot(1,6,4)\n",
    "            ax = plt.gca()\n",
    "            im = ax.imshow(attr_ggcam)\n",
    "            plt.axis('off')\n",
    "            divider = make_axes_locatable(ax)\n",
    "            cax = divider.append_axes(\"bottom\", size=\"5%\", pad=0.05)\n",
    "            plt.colorbar(im, cax=cax, orientation=\"horizontal\")\n",
    "            \n",
    "            plt.subplot(1,6,5)\n",
    "            ax = plt.gca()\n",
    "            im = ax.imshow(attr_ig)\n",
    "            plt.axis('off')\n",
    "            divider = make_axes_locatable(ax)\n",
    "            cax = divider.append_axes(\"bottom\", size=\"5%\", pad=0.05)\n",
    "            plt.colorbar(im, cax=cax, orientation=\"horizontal\")\n",
    "            \n",
    "            plt.subplot(1,6,6)\n",
    "            ax = plt.gca()\n",
    "            im = ax.imshow(attr_ixg)\n",
    "            plt.axis('off')\n",
    "            divider = make_axes_locatable(ax)\n",
    "            cax = divider.append_axes(\"bottom\", size=\"5%\", pad=0.05)\n",
    "            plt.colorbar(im, cax=cax, orientation=\"horizontal\")\n",
    "            \n",
    "            \n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fc7c26-0e2c-47c8-9198-b522d3694fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_classifier_w_AE_interp(\n",
    "    test_loader,\n",
    "    NetAE,\n",
    "    Net,\n",
    "    dtype = torch.cuda.FloatTensor,\n",
    "    device='cuda',\n",
    "    n_show = 3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c688d2-5792-40be-9862-5a62c5e63312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tangent_space(NetAE, \n",
    "    xin,\n",
    "    orth = True,\n",
    "    device='cuda',\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "):\n",
    "    '''\n",
    "    xin: has to be single image as a batch\n",
    "    '''\n",
    "    NetAE.to(device)\n",
    "    NetAE.type(dtype)\n",
    "    for param in NetAE.parameters():\n",
    "        param.require_grad = True\n",
    "        \n",
    "    xin = xin.to(device)\n",
    "    z = NetAE.encode(xin)\n",
    "    z = z.detach()\n",
    "    z.requires_grad = True\n",
    "    out = NetAE.decode(z)\n",
    "    \n",
    "    out = out.squeeze()      # remove batch dimension\n",
    "    output_shape = out.shape # store original output shape\n",
    "    out = out.reshape(-1)    # and transform the output into a vector\n",
    "    latent_dim = z.reshape(-1).shape[0]\n",
    "    tangent_space = torch.zeros((latent_dim, out.shape[0]))\n",
    "    for i in range(out.shape[0]):\n",
    "        out[i].backward(retain_graph=True)\n",
    "        tangent_space[:, i] = z.grad.reshape(-1)\n",
    "        z.grad.zero_()\n",
    "    tangent_space = tangent_space.reshape((-1, *output_shape)) # tangent space in model output shape\n",
    "#             if transform is not None: # transform the output space\n",
    "#                 tangent_space = transform(tangent_space)\n",
    "    orth_tangent_space = True\n",
    "    if orth:                 # orthogonalize the tangent space. note that the numerical dimension of the \n",
    "                             # tangent space might be less than the dimension of the latent space\n",
    "        orth_shape = (-1, *tangent_space.shape[1:])  \n",
    "        T = tangent_space.reshape((latent_dim, -1))\n",
    "        orth_tangent_space = torch.zeros_like(T)\n",
    "        T = scipy.linalg.orth(T.T).T\n",
    "        T = torch.Tensor(T)\n",
    "        for i in range(T.shape[0]):                        # the remaining dimensions are filled with zeros\n",
    "            orth_tangent_space[i, :] = T[i, :]\n",
    "        orth_tangent_space = orth_tangent_space.reshape(orth_shape)\n",
    "    return tangent_space, orth_tangent_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cf8715-bd63-45b2-9833-80fd6ee9e03f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def project_into_tangent_space(tangent_space, vector):\n",
    "    dim = tangent_space.shape[0]\n",
    "    coeff = torch.zeros(dim)\n",
    "    for i in range(dim):\n",
    "        coeff[i] = tangent_space[i, :, :, :].flatten() @ vector.flatten()\n",
    "    gradient_in_tangent_space = (coeff @ tangent_space.reshape((dim, -1))).reshape((3, 256, 224))\n",
    "    return gradient_in_tangent_space\n",
    "\n",
    "\n",
    "fraction_gradient_in_tangent_space = []\n",
    "fraction_integrated_gradient_in_tangent_space = []\n",
    "fraction_guided_gc_in_tangent_space = []\n",
    "fraction_gshap_in_tangent_space = []\n",
    "\n",
    "for idx, (xin, yout) in tqdm(enumerate(test_loader)):\n",
    "    n_batch = xin.shape[0]\n",
    "    for idy in range(n_batch):\n",
    "        if os.path.exists('out/pneumonia_tspace_{}_{}.npy'.format(idx, idy)) and os.path.exists('out/pneumonia_otspace_{}_{}.npy'.format(idx, idy)):\n",
    "            tangent_space, orth_tangent_space = np.load('out/pneumonia_tspace_{}_{}.npy'.format(idx, idy)), np.load('out/pneumonia_otspace_{}_{}.npy'.format(idx, idy))\n",
    "        else:\n",
    "            tangent_space, orth_tangent_space = compute_tangent_space(NetAE, xin[idy].unsqueeze(0), orth=True, device='cuda', dtype = torch.cuda.FloatTensor)\n",
    "            np.save('out/pneumonia_tspace_{}_{}.npy'.format(idx, idy), tangent_space)\n",
    "            np.save('out/pneumonia_otspace_{}_{}.npy'.format(idx, idy), orth_tangent_space)\n",
    "        print('tspace done!')\n",
    "\n",
    "        out, _ = NetAE(xin[idy].unsqueeze(0).cuda())\n",
    "        out = out.detach()\n",
    "        out.requires_grad = True\n",
    "\n",
    "        prediction = Net(out)[0]\n",
    "        c = torch.argmax(F.log_softmax(prediction))\n",
    "        if c.item() == 1 and c.item() == yout[idy].item():\n",
    "            prediction[c].backward()\n",
    "            grad = deepcopy(out.grad.detach().reshape((3, 256, 224)))\n",
    "\n",
    "            out.grad.zero_()\n",
    "            ig = IntegratedGradients(Net)\n",
    "            attr, delta = ig.attribute(out, target=c, return_convergence_delta=True)\n",
    "            attr = deepcopy(attr.detach().reshape((3, 256, 224)))\n",
    "\n",
    "            guided_gc = GuidedGradCam(Net, Net.features[10])\n",
    "            attr1 = guided_gc.attribute(out, target=c)\n",
    "            attr1 = deepcopy(attr1.detach().reshape((3, 256, 224)))\n",
    "            \n",
    "            gradient_shap = GradientShap(Net)\n",
    "            # choosing baselines randomly\n",
    "            baselines = torch.randn(20, 3, 256, 224).cuda()\n",
    "            # Computes gradient shap for the input\n",
    "            attr2 = gradient_shap.attribute(out, baselines, target=c)\n",
    "\n",
    "            grad_in_tsp = project_into_tangent_space(torch.tensor(orth_tangent_space).to('cpu').float(), grad.to('cpu').float())\n",
    "            ig_in_tsp = project_into_tangent_space(torch.tensor(orth_tangent_space).to('cpu').float(), attr.to('cpu').float())\n",
    "            guided_gc_in_tsp = project_into_tangent_space(torch.tensor(orth_tangent_space).to('cpu').float(), attr1.to('cpu').float())\n",
    "            gshap_in_tsp = project_into_tangent_space(torch.tensor(orth_tangent_space).to('cpu').float(), attr2.to('cpu').float())\n",
    "\n",
    "            fgtsp = np.linalg.norm(grad_in_tsp.cpu().numpy())/np.linalg.norm(grad.cpu().numpy())\n",
    "            figtsp = np.linalg.norm(ig_in_tsp.cpu().numpy())/np.linalg.norm(attr.cpu().numpy())\n",
    "            fguidedgctsp = np.linalg.norm(guided_gc_in_tsp.cpu().numpy())/np.linalg.norm(attr1.cpu().numpy())\n",
    "            fgshaptsp = np.linalg.norm(gshap_in_tsp.cpu().numpy())/np.linalg.norm(attr2.cpu().numpy())\n",
    "\n",
    "            fraction_gradient_in_tangent_space.append(fgtsp)\n",
    "            fraction_integrated_gradient_in_tangent_space.append(figtsp)\n",
    "            fraction_guided_gc_in_tangent_space.append(fguidedgctsp)\n",
    "            fraction_gshap_in_tangent_space.append(fgshaptsp)\n",
    "            print(fgtsp)\n",
    "            print(figtsp)\n",
    "            print(fguidedgctsp)\n",
    "            print(fgshaptsp)\n",
    "            print('***')\n",
    "            np.save('out/pneumonia_fgtsp.npy', fraction_gradient_in_tangent_space)\n",
    "            np.save('out/pneumonia_figtsp.npy', fraction_integrated_gradient_in_tangent_space)\n",
    "            np.save('out/pneumonia_fguidedgctsp.npy', fraction_guided_gc_in_tangent_space)\n",
    "            np.save('out/pneumonia_fgshaptsp.npy', fraction_gshap_in_tangent_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3d06c5-22f6-4821-a208-6d2760142ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load results of computation\n",
    "fraction_gradient_in_tangent_space = np.load('out/pneumonia_fgtsp.npy')\n",
    "fraction_integrated_gradient_in_tangent_space = np.load('out/pneumonia_figtsp.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6a30cd-cf1e-447f-9fb9-4a77bc7a6d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "for values, name in [(fraction_gradient_in_tangent_space, 'Fraction of gradient in\\ntangent space'),\n",
    "                     (fraction_integrated_gradient_in_tangent_space, 'Fraction of integrated gradient in\\ntangent space'),\n",
    "                     (fraction_guided_gc_in_tangent_space, 'Fraction of guided_gc in\\ntangent space'),\n",
    "                     (fraction_gshap_in_tangent_space, 'Fraction of gshap in\\ntangent space'),\n",
    "                    ]:\n",
    "    sns.distplot(values, kde=False)\n",
    "    plt.xlim([0, 1])\n",
    "plt.title(f'Fraction in Tangent Space, Gradient shap vs. guded gcam vs. Raw Gradient vs. Integrated Gradients')\n",
    "plt.xlim([0.05, 0.45])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951f917a-71bd-4938-810b-1590e6997563",
   "metadata": {},
   "outputs": [],
   "source": [
    "for values, name in [(fraction_gradient_in_tangent_space, 'Fraction of gradient in\\ntangent space'),\n",
    "                     (fraction_integrated_gradient_in_tangent_space, 'Fraction of integrated gradient in\\ntangent space'),\n",
    "                     (fraction_guided_gc_in_tangent_space, 'Fraction of guided_gc in\\ntangent space')\n",
    "                    ]:\n",
    "    sns.distplot(values, kde=False)\n",
    "    plt.xlim([0, 1])\n",
    "plt.title(f'Fraction in Tangent Space, Raw Gradient vs. Integrated Gradients')\n",
    "plt.xlim([0.15, 0.45])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
